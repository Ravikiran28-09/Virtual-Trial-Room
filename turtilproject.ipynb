{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d0d49-5445-492e-a59b-1190c2f7595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from keras.models import load_model\n",
    "import time\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('xyz.h5')\n",
    "\n",
    "# Define class labels for Fashion MNIST dataset\n",
    "class_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "male_shirt_images = [\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\1.png\", -1),\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\2.png\", -1),\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\3.png\", -1),\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\4.png\", -1),\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\5.png\", -1),\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\6.png\", -1),\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\7.png\", -1),\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\8.png\", -1),\n",
    "]\n",
    "\n",
    "female_shirt_images = [\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\10.png\", -1),\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\11.png\", -1),\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\12.png\", -1),\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\13.png\", -1),\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\16.png\", -1),\n",
    "    cv2.imread(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\Resources\\Shirts\\15.png\", -1)\n",
    "]\n",
    "\n",
    "if any(image is None for image in male_shirt_images + female_shirt_images):\n",
    "    raise ValueError(\"Error: Could not load one or more shirt images\")\n",
    "\n",
    "# Initialize Mediapipe pose and hand detection\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, enable_segmentation=False, min_detection_confidence=0.3)\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.3, min_tracking_confidence=0.5)\n",
    "\n",
    "# Function to preprocess the webcam input\n",
    "def preprocess_webcam_input(frame):\n",
    "    # Resize the frame to match the input size of the model (28x28)\n",
    "    resized_frame = cv2.resize(frame, (28, 28))\n",
    "    # Convert the frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Normalize pixel values to be in the range [0, 1]\n",
    "    normalized = gray_frame.astype('float32') / 255\n",
    "    # Reshape the input data to match the model's input shape\n",
    "    input_data = normalized.reshape(1, 28, 28, 1)\n",
    "    return input_data\n",
    "\n",
    "# Function to overlay the shirt image on the frame\n",
    "def overlay_shirt(frame, shirt_image, shoulders, upper_body_height):\n",
    "    (left_shoulder, right_shoulder) = shoulders\n",
    "    shoulder_width = abs(right_shoulder[0] - left_shoulder[0])\n",
    "    shirt_width = int(shoulder_width * 1.8)  # Increase the width scaling factor\n",
    "    shirt_height = int(shirt_image.shape[0] * (shirt_width / shirt_image.shape[1]))\n",
    "    \n",
    "    # Calculate the midpoint between the shoulders for centering the shirt\n",
    "    mid_shoulder_x = int((left_shoulder[0] + right_shoulder[0]) / 2)\n",
    "    shirt_x = mid_shoulder_x - int(shirt_width / 2)\n",
    "    shirt_y = left_shoulder[1] - int(0.25 * upper_body_height)  # Start the shirt slightly above the shoulders\n",
    "    \n",
    "    # Ensure the shirt image fits within the frame\n",
    "    if shirt_x < 0:\n",
    "        shirt_x = 0\n",
    "    if shirt_y < 0:\n",
    "        shirt_y = 0\n",
    "    if shirt_x + shirt_width > frame.shape[1]:\n",
    "        shirt_width = frame.shape[1] - shirt_x\n",
    "    if shirt_y + shirt_height > frame.shape[0]:\n",
    "        shirt_height = frame.shape[0] - shirt_y\n",
    "    \n",
    "    # Ensure positive dimensions for resizing\n",
    "    if shirt_width > 0 and shirt_height > 0:\n",
    "        resized_shirt = cv2.resize(shirt_image, (shirt_width, shirt_height))\n",
    "        alpha_s = resized_shirt[:, :, 3] / 255.0\n",
    "        alpha_l = 1.0 - alpha_s\n",
    "\n",
    "        for c in range(0, 3):\n",
    "            frame[shirt_y:shirt_y+shirt_height, shirt_x:shirt_x+shirt_width, c] = (\n",
    "                alpha_s * resized_shirt[:, :, c] + alpha_l * frame[shirt_y:shirt_y+shirt_height, shirt_x:shirt_x+shirt_width, c]\n",
    "            )\n",
    "\n",
    "# Function to classify clothes from webcam feed\n",
    "def classify_clothes_from_webcam(gender, root):\n",
    "    # Select shirt images based on gender\n",
    "    if gender == 'male':\n",
    "        shirt_images = male_shirt_images\n",
    "    elif gender == 'female':\n",
    "        shirt_images = female_shirt_images\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gender selection\")\n",
    "    \n",
    "    # Open the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    current_shirt_index = 0\n",
    "    hand_detected = False\n",
    "    last_hand_detection_time = 0\n",
    "    cooldown_period = 1  # Cooldown period in seconds\n",
    "    \n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Preprocess the frame\n",
    "        input_data = preprocess_webcam_input(frame)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(input_data)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        label = class_labels[predicted_class]\n",
    "        \n",
    "        # Display the predicted label on the frame\n",
    "        cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # Use Mediapipe to detect pose landmarks\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pose_results = pose.process(frame_rgb)\n",
    "        \n",
    "        if pose_results.pose_landmarks:\n",
    "            landmarks = pose_results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates of left and right shoulders and hips\n",
    "            left_shoulder = (int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * frame.shape[1]),\n",
    "                             int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * frame.shape[0]))\n",
    "            right_shoulder = (int(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * frame.shape[1]),\n",
    "                              int(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * frame.shape[0]))\n",
    "            left_hip = (int(landmarks[mp_pose.PoseLandmark.LEFT_HIP].x * frame.shape[1]),\n",
    "                        int(landmarks[mp_pose.PoseLandmark.LEFT_HIP].y * frame.shape[0]))\n",
    "            right_hip = (int(landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x * frame.shape[1]),\n",
    "                         int(landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y * frame.shape[0]))\n",
    "            \n",
    "            # Calculate upper body height (distance between shoulders and hips)\n",
    "            upper_body_height = int((left_hip[1] + right_hip[1]) / 2 - (left_shoulder[1] + right_shoulder[1]) / 2)\n",
    "            \n",
    "            # Overlay the shirt image if a shirt is detected\n",
    "            if label in ['Shirt', 'T-shirt/top', 'Dress']:\n",
    "                overlay_shirt(frame, shirt_images[current_shirt_index], (left_shoulder, right_shoulder), upper_body_height)\n",
    "        \n",
    "        # Use Mediapipe to detect hand landmarks\n",
    "        hand_results = hands.process(frame_rgb)\n",
    "        \n",
    "        # Check for hands and manage the cooldown period\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            if not hand_detected:\n",
    "                current_time = time.time()\n",
    "                print(f\"Hand detected at {current_time}, last detection at {last_hand_detection_time}\")\n",
    "                if current_time - last_hand_detection_time > cooldown_period:\n",
    "                    print(\"Changing shirt image\")\n",
    "                    current_shirt_index = (current_shirt_index + 1) % len(shirt_images)\n",
    "                    last_hand_detection_time = current_time\n",
    "            hand_detected = True\n",
    "        else:\n",
    "            hand_detected = False\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('Clothes Classification', frame)\n",
    "        \n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Show the gender selection frame again\n",
    "    gender_frame.pack(pady=50)\n",
    "\n",
    "# Function to handle the start button click\n",
    "def start_virtual_trial_room():\n",
    "    # Hide the home page\n",
    "    home_frame.pack_forget()\n",
    "\n",
    "    # Show the gender selection frame\n",
    "    gender_frame.pack(pady=50)\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Virtual Trial Room\")\n",
    "\n",
    "# Set the window size\n",
    "root.geometry(\"400x400\")\n",
    "\n",
    "# Load images for male and female\n",
    "try:\n",
    "    male_image = Image.open(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\male.png\")\n",
    "    female_image = Image.open(r\"C:\\Users\\rk267\\OneDrive\\Desktop\\vtr\\female.png\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading images: {e}\")\n",
    "    root.destroy()\n",
    "    exit(1)\n",
    "\n",
    "# Resize images if necessary\n",
    "male_image = male_image.resize((100, 100), Image.LANCZOS)\n",
    "female_image = female_image.resize((100, 100), Image.LANCZOS)\n",
    "\n",
    "# Convert images to Tkinter PhotoImage\n",
    "male_icon = ImageTk.PhotoImage(male_image)\n",
    "female_icon = ImageTk.PhotoImage(female_image)\n",
    "\n",
    "# Create the home frame\n",
    "home_frame = tk.Frame(root)\n",
    "home_frame.pack(pady=50)\n",
    "\n",
    "# Create and place the title label in the home frame\n",
    "title_label = tk.Label(home_frame, text=\"Virtual Trial Room\", font=(\"Helvetica\", 24))\n",
    "title_label.pack(pady=10)\n",
    "\n",
    "# Create and place the start button in the home frame\n",
    "start_button = tk.Button(home_frame, text=\"Start\", font=(\"Helvetica\", 18), command=start_virtual_trial_room)\n",
    "start_button.pack(pady=20)\n",
    "\n",
    "# Create the gender selection frame\n",
    "gender_frame = tk.Frame(root)\n",
    "\n",
    "# Create and place the gender title label in the gender frame\n",
    "gender_label = tk.Label(gender_frame, text=\"Gender\", font=(\"Helvetica\", 24))\n",
    "gender_label.pack(pady=10)\n",
    "\n",
    "# Create a frame for the gender buttons and images\n",
    "gender_buttons_frame = tk.Frame(gender_frame)\n",
    "gender_buttons_frame.pack(pady=20)\n",
    "\n",
    "# Create and place the male button and image in the gender buttons frame\n",
    "male_button = tk.Button(gender_buttons_frame, image=male_icon, text=\"Male\", compound=tk.TOP, font=(\"Helvetica\", 18), width=120,\n",
    "                        command=lambda: classify_clothes_from_webcam('male', root))\n",
    "male_button.image = male_icon  # Keep a reference to the image to prevent garbage collection\n",
    "male_button.pack(side=tk.LEFT, padx=20)\n",
    "\n",
    "# Create and place the female button and image in the gender buttons frame\n",
    "female_button = tk.Button(gender_buttons_frame, image=female_icon, text=\"Female\", compound=tk.TOP, font=(\"Helvetica\", 18), width=120,\n",
    "                          command=lambda: classify_clothes_from_webcam('female', root))\n",
    "female_button.image = female_icon  # Keep a reference to the image to prevent garbage collection\n",
    "female_button.pack(side=tk.RIGHT, padx=20)\n",
    "\n",
    "# Keep references to the images to prevent garbage collection\n",
    "root.male_icon = male_icon\n",
    "root.female_icon = female_icon\n",
    "\n",
    "# Run the application\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
